# YoptaScript Grammar Overview

YoptaScript — экспериментальный язык со сленговым синтаксисом, который мы компилируем в современный ES2025 JavaScript. Этот документ фиксирует договорённости о том, какие лексемы и конструкции поддерживает язык. Формальная запись нужна, чтобы лексер, парсер и остальные фазы компилятора работали согласованно.

Ниже собраны правила для двух уровней анализа:
- **Лексический** — допустимые символы, ключевые слова, литералы, операторы.
- **Синтаксический** — из каких конструкций состоит программа и как они комбинируются.

## Character Set

- **Letters**: кириллица (`А-Я`, `а-я`, включая `ё`) и латиница (`A-Z`, `a-z`).
- **Digits**: `0-9`.
- **Separators**: пробел, табуляция, перевод строки (`\n`), возврат каретки (`\r`).
- **Punctuation**: ASCII-символы `(){}[],.;:` и спецсимволы `@#$%^&*!?`.
- **Comments**: строковые `# ...` и блочные `/* ... */` — лексер пропускает их.
- **Unicode**: любые прочие символы считаются ошибкой и должны порождать `Diagnostic`.

## Keyword Mapping (JS → YoptaScript)

| JavaScript | YoptaScript aliases |
|------------|---------------------|
| `break` | `харэ` |
| `case` | `лещ`, `аеслинайду` |
| `catch` | `гоп`, `аченетак`, `аченитак`, `ачёнетак` |
| `class` | `клёво`, `клево` |
| `const` | `ясенХуй`, `ЯсенХуй` |
| `continue` | `двигай` |
| `debugger` | `логопед` |
| `default` | `пахану`, `апохуй`, `наотыбись` |
| `delete` | `ёбнуть`, `ебнуть` |
| `do` | `крч` |
| `else` | `иливжопураз` |
| `enum` | `еээ`, `Еээ` |
| `export` | `предъява` |
| `extends` | `батя` |
| `finally` | `тюряжка` |
| `for` | `го` |
| `function` | `йопта` |
| `if` | `вилкойвглаз` |
| `import` | `спиздить` |
| `in` | `чоунастут` |
| `instanceof` | `шкура` |
| `new` | `гыйбать`, `захуярить` |
| `return` | `отвечаю` |
| `super` | `яга` |
| `switch` | `естьчо` |
| `this` | `тырыпыры` |
| `throw` | `пнх` |
| `try` | `хапнуть`, `побратски`, `пабрацки`, `пабратски` |
| `typeof` | `чезажижан` |
| `var` | `гыы` |
| `void` | `куку` |
| `while` | `потрещим` |
| `with` | `хзйопт` |

### Strict / Module Keywords

| JavaScript | YoptaScript aliases |
|------------|---------------------|
| `let` | `участковый` |
| `static` | `попонятия` |
| `yield` | `поебалу` |
| `await` | `сидетьНахуй` |
| `async` | `ассо` |
| `using` | `юзай` |

### Literals and Built-ins Treated as Keywords

| JavaScript | YoptaScript aliases |
|------------|---------------------|
| `null` | `нуллио`, `порожняк` |
| `true` | `трулио`, `чётко`, `четко`, `чотко` |
| `false` | `нетрулио`, `пиздишь`, `нечётко`, `нечетко`, `нечотко` |
| `undefined` | `неибу` |
| `NaN` | `нихуя` |

### Future Reserved Keywords

| JavaScript | YoptaScript aliases |
|------------|---------------------|
| `implements` | `силикон` |
| `interface` | `хуёво`, `хуево` |
| `package` | `клеёнка`, `клеенка` |
| `private` | `мой` |
| `protected` | `подкрыша` |
| `public` | `ебанное` |
| `arguments`* | `аргос` |
| `eval`* | `ебал` |

> *`arguments` и `eval` — специальные идентификаторы строгого режима; мы резервируем их, чтобы предотвращать ошибки времени выполнения.

### Дополнительные формы

- `function*` → `пиздюли` — объявление генератора.
- `yield*` → `поебалуна` — делегирование генератора.
- `of` → `сашаГрей` — используется в конструкции `for ... of`.

## Operators (ES2025 + Stage 3)

Лексер должен распознавать следующие комбинации символов как атомарные токены:

- Арифметика: `+`, `-`, `*`, `/`, `%`, `**`, `**=`.
- Присваивания: `=`, `+=`, `-=`, `*=`, `/=`, `%=`, `**=`, `&&=`, `||=`, `??=`.
- Инкременты: `++`, `--`.
- Сравнения: `==`, `===`, `!=`, `!==`, `<`, `>`, `<=`, `>=`.
- Логика: `&&`, `||`, `??`, `!`.
- Опциональные цепочки: `?.`, `?.[]`, `?.()` (лексер должен выделять `?.`, `?.[` и `?.(` как отдельные токены).
- Nullish/optional присваивания: `??=`, `?.=` (если встретится).
- Pipeline: `|>`.
- Лямбды: `=>`.
- Decorator: `@`.
- Records & Tuples: `#{`, `#[`, а также закрывающие `}` и `]`.
- Деструктуризация: `...` (spread/rest оператор).
- Сравнение присваивания (stage 3): `:=`.
- Ресурсный менеджмент: `using` + потенциальная комбинация `await using`.

Для одиночных символов (`(`, `)`, `{`, `}`, `[`, `]`, `,`, `;`, `:`) лексер генерирует токены пунктуации. Для операторов с несколькими символами важно проверять максимально длинное совпадение (жадный матч), чтобы `??=` не распалось на `??` и `=`.

Эти инструкции задают полную «азбуку» для стадий ES2025 и всех Stage 3 предложений, которые могут попасть в стандарт.

## Identifiers

- Первая позиция: буква (кириллица/латиница, включая `ё`) или подчёркивание (`_`).
- Продолжение: буквы, цифры, подчёркивания. Разрешаем смешение кириллицы и латиницы.
- Лексер обязан нормализовать последовательность в соответствии с Unicode Scalar Values; суррогатные пары запрещены.
- После извлечения идентификатора он сверяется с таблицей ключевых слов. Если совпадение найдено, возвращаем `TokenKind::Keyword`; иначе — `TokenKind::Identifier`.

## Numeric Literals

- **Десятичные**: `0`, `123`, `1_000`, `3.14`, `0.5`, `10.` (безопасно), `1e9`, `1.2e-3`.
- **Шестнадцатеричные**: `0xFF`, `0xDEAD_BEEF`.
- **Двоичные**: `0b1010_0011`.
- **Восьмеричные**: `0o755`, `0o12_34`.
- Разделители `_` разрешены между цифрами, но не в начале/конце и не рядом с префиксами (`0x`, `0b`, `0o`) или экспоненцией (`1e_9` запрещено).
- Сигнатуры `+123`/`-123` не часть литерала — знак обрабатывается как оператор.

## String and Template Literals

- Обычные строки: `'...'` и `"..."`. Поддерживаются escape-последовательности `\n`, `\r`, `\t`, `\0`, `\'`, `\"`, `\\`, `\xNN`, `\u{NNNN}`.
- Шаблонные строки: `` ` ... ${expr} ... ` `` с теми же escape. Внутри `${}` разрешены все выражения языка.
- Stage 3 расширения (например, `\u{...}` в шаблонах или line terminators) поддерживаем сразу — лексер не должен ломаться на них.
- Нестрогие многострочные литералы не разрешены; многострочность достигается через шаблоны.

## Whitespace and Comments

- Пробельные символы (` `, `\t`, `\r`, `\n`) отделяют токены, но сами токены не создают.
- Однострочные комментарии `# ...` и `// ...` продолжаются до конца строки.
- Многострочные `/* ... */` могут быть вложенными? — нет, следуем поведению JS: вложения приводит к ошибке «unterminated comment».
- Лексер должен игнорировать комменты, но фиксировать `Span` начала и конца, чтобы сообщать о незакрытых конструкциях.

## Source Locations

- Каждый токен имеет `Span { start, end }`, где `start` и `end` — индексы байт в UTF-8 исходника.
- Для отчётов об ошибках дополнительно храним таблицу `byte_offset → (line, column)`.
- Diagnostic сообщает пользователю исходную позицию, а backend использует те же span’ы для генерации source map.
